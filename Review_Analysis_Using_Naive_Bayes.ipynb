{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Review Analysis Using Naive Bayes.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KA-mmz/AI-Project/blob/master/Review_Analysis_Using_Naive_Bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3nWI86d2U0X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "9f5b8ce6-928a-49bb-806c-f192211b2a4b"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas_profiling\n",
        "!pip install stop_words\n",
        "\n",
        "#Text Filtering\n",
        "from collections import Counter\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from stop_words import get_stop_words\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import sent_tokenize, word_tokenize\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import re\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: stop_words in /usr/local/lib/python3.6/dist-packages (2018.7.23)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyNAfKKQ7TgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Kaggle Data and Notebook\n",
        "rev=pd.read_csv(\"Reviews.csv\",index_col=False)\n",
        "col=['Clothing ID','Age','Title','Review Text','Rating','Positive Feedback Count']\n",
        "df=pd.DataFrame(data=rev,columns=col)\n",
        "####################################################\n",
        "a = df['Review Text'].str.lower().str.cat(sep=' ')\n",
        "b = re.sub('[^A-Za-z]+', ' ', a)\n",
        "stop_words = list(get_stop_words('en'))         \n",
        "nltk_words = list(stopwords.words('english'))   \n",
        "stop_words.extend(nltk_words)\n",
        "word_tokens = word_tokenize(b)\n",
        "filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
        "filtered_sentence = []\n",
        "for w in word_tokens:\n",
        "    if w not in stop_words:\n",
        "        filtered_sentence.append(w)\n",
        "\n",
        "# Remove characters which have length less than 2  \n",
        "without_single_chr = [word for word in filtered_sentence if len(word) > 2]\n",
        "\n",
        "# Remove numbers\n",
        "cleaned_data_title = [word for word in without_single_chr if not word.isnumeric()]        \n",
        "\n",
        "# Calculate frequency distribution\n",
        "word_dist = nltk.FreqDist(cleaned_data_title)\n",
        "rslt = pd.DataFrame(word_dist.most_common(100),\n",
        "                    columns=['Word', 'Frequency'])\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.set_style(\"whitegrid\")\n",
        "ax = sns.barplot(x=\"Word\",y=\"Frequency\", data=rslt.head(10))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04vMXhxz8T_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tagging\n",
        "\n",
        "from textblob import TextBlob\n",
        "bloblist_desc = list()\n",
        "df_review=df['Review Text'].astype(str)\n",
        "for row in df_review:\n",
        "    blob = TextBlob(row)\n",
        "    bloblist_desc.append((row,blob.sentiment.polarity, blob.sentiment.subjectivity))\n",
        "    df_polarity_desc = pd.DataFrame(bloblist_desc, columns = ['Review','sentiment','polarity'])\n",
        " \n",
        "def f(df_polarity_desc):\n",
        "    if df_polarity_desc['sentiment'] > 0:\n",
        "        val = \"Positive Review\"\n",
        "    elif df_polarity_desc['sentiment'] == 0:\n",
        "        val = \"Neutral Review\"\n",
        "    else:\n",
        "        val = \"Negative Review\"\n",
        "    return val\n",
        "\n",
        "df_polarity_desc['Sentiment_Type'] = df_polarity_desc.apply(f, axis=1)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.set_style(\"whitegrid\")\n",
        "ax = sns.countplot(x=\"Sentiment_Type\", data=df_polarity_desc)\n",
        "\n",
        "pos=df_polarity_desc[df_polarity_desc['Sentiment_Type']=='Positive Review']\n",
        "neg=df_polarity_desc[df_polarity_desc['Sentiment_Type']=='Negative Review']\n",
        "\n",
        "import string\n",
        "def text_process(review):\n",
        "    nopunc=[word for word in review if word not in string.punctuation]\n",
        "    nopunc=''.join(nopunc)\n",
        "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
        "\n",
        "df['Review Text'].head(5).apply(text_process)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB9IC4P57l2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data process for NB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "df=df.dropna(axis=0,how='any')\n",
        "rating_class = df[(df['Rating'] == 1) | (df['Rating'] == 5)]\n",
        "X_review=rating_class['Review Text']\n",
        "y=rating_class['Rating']\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "bow_transformer=CountVectorizer(analyzer=text_process).fit(X_review)\n",
        "X_review = bow_transformer.transform(X_review)\n",
        "\n",
        "#spliting\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_review, y, test_size=0.3, random_state=101)\n",
        "\n",
        "#NB\n",
        "nb = MultinomialNB()\n",
        "nb.fit(X_train, y_train)\n",
        "predict=nb.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vn6ZiSg_6YUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#accuracy\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "print(confusion_matrix(y_test, predict))\n",
        "print('\\n')\n",
        "print(classification_report(y_test, predict))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2k-Hqhj6bXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rating_positive=df['Review Text'][3]\n",
        "rating_positive_transformed = bow_transformer.transform([rating_positive])\n",
        "nb.predict(rating_positive_transformed)[0]\n",
        "\n",
        "rating_negative=df['Review Text'][61]\n",
        "rating_negative_transformed = bow_transformer.transform([rating_negative])\n",
        "nb.predict(rating_negative_transformed)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}